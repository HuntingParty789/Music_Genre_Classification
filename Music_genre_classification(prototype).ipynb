{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17c6e50-08b7-4ca0-9ba1-a2f21ac1ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording finished.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load pre-trained model and label encoder\n",
    "model = load_model('MSTCNN_model.h5')\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# Define parameters\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30\n",
    "NUM_MFCC = 13\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "EXPECTED_MFCC_LEN = 1320  # Expected number of frames in MFCC for the model\n",
    "\n",
    "# Variable to store last recorded audio\n",
    "last_audio = None\n",
    "\n",
    "# Record real-time audio\n",
    "def record_audio(duration=DURATION, sr=SAMPLE_RATE):\n",
    "    global last_audio\n",
    "    print(\"Recording started...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording finished.\")\n",
    "    last_audio = np.squeeze(audio)  # Store the recorded audio for playback\n",
    "    return last_audio\n",
    "\n",
    "# Process audio to MFCC with padding/truncation\n",
    "def preprocess_audio(audio, sr=SAMPLE_RATE, num_mfcc=NUM_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH, expected_len=EXPECTED_MFCC_LEN):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    # Pad or truncate to ensure consistent length\n",
    "    if mfcc.shape[1] < expected_len:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, expected_len - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :expected_len]\n",
    "    return np.expand_dims(mfcc.T, axis=0)  # Add batch dimension for model input\n",
    "\n",
    "# Classify genre of audio\n",
    "def classify_genre(audio_mfcc):\n",
    "    prediction = model.predict(audio_mfcc)\n",
    "    genre_index = np.argmax(prediction, axis=1)\n",
    "    genre_label = encoder.inverse_transform(genre_index)\n",
    "    confidence = prediction[0][genre_index[0]] * 100  # Confidence in percentage\n",
    "    return genre_label[0], confidence\n",
    "\n",
    "# GUI functions\n",
    "def classify_audio():\n",
    "    audio = record_audio()  # Record audio\n",
    "    audio_mfcc = preprocess_audio(audio)  # Process to MFCC\n",
    "    genre, confidence = classify_genre(audio_mfcc)  # Predict genre\n",
    "    messagebox.showinfo(\"Genre Classification\", f\"Predicted Genre: {genre} \\nConfidence: {confidence:.2f}%\")\n",
    "\n",
    "def save_audio():\n",
    "    global last_audio\n",
    "    if last_audio is not None:\n",
    "        file_name = f\"recording_{np.random.randint(1000, 9999)}.wav\"\n",
    "        sf.write(file_name, last_audio, SAMPLE_RATE)  # Save using soundfile\n",
    "        messagebox.showinfo(\"Save Recording\", f\"Audio saved as {file_name}\")\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"No audio recorded to save.\")\n",
    "\n",
    "def play_audio():\n",
    "    global last_audio\n",
    "    if last_audio is not None:\n",
    "        sd.play(last_audio, samplerate=SAMPLE_RATE)  # Play back the last recorded audio\n",
    "        sd.wait()  # Wait until playback finishes\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"No audio recorded to play.\")\n",
    "\n",
    "# GUI interface\n",
    "root = tk.Tk()\n",
    "root.title(\"Real-Time Genre Classification\")\n",
    "\n",
    "# Create GUI buttons\n",
    "classify_button = tk.Button(root, text=\"Record and Classify\", command=classify_audio)\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "save_button = tk.Button(root, text=\"Save Recording\", command=save_audio)\n",
    "save_button.pack(pady=10)\n",
    "\n",
    "play_button = tk.Button(root, text=\"Play Recording\", command=play_audio)\n",
    "play_button.pack(pady=10)\n",
    "\n",
    "exit_button = tk.Button(root, text=\"Exit\", command=root.quit)\n",
    "exit_button.pack(pady=10)\n",
    "\n",
    "# Run the GUI loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af5942d-4f90-46bd-a1f4-9e4374ef2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Define genres and encoder\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(genres)\n",
    "\n",
    "# Save the encoder\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60cd480-884b-476e-9fc9-c76179579d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Adjust preprocess_audio function to pad MFCCs\n",
    "def preprocess_audio(audio, sr=SAMPLE_RATE, num_mfcc=NUM_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH, expected_len=1320):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    # Pad or truncate to ensure consistent length\n",
    "    if mfcc.shape[1] < expected_len:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, expected_len - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :expected_len]\n",
    "    return np.expand_dims(mfcc.T, axis=0)  # Add batch dimension for model input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbc22a-f011-4290-93c4-de817d384e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
