{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438c1ea9-b6a3-4c6f-a21e-cd0c144eedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, ttk\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Load pre-trained model and label encoder\n",
    "model = load_model('MSTCNN_model.h5')\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# Define parameters\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30\n",
    "NUM_MFCC = 13\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "EXPECTED_MFCC_LEN = 1320\n",
    "\n",
    "# Variable to store last recorded audio and classification history\n",
    "last_audio = None\n",
    "classification_history = []\n",
    "\n",
    "# Tkinter root setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Music Genre Classifier\")\n",
    "root.geometry(\"900x600\")\n",
    "root.config(bg=\"#1e1e2e\")\n",
    "\n",
    "# Notebook (Tabbed layout)\n",
    "notebook = ttk.Notebook(root)\n",
    "notebook.pack(expand=True, fill='both', pady=10)\n",
    "\n",
    "# Tabs\n",
    "tab_main = ttk.Frame(notebook)\n",
    "tab_visualization = ttk.Frame(notebook)\n",
    "tab_results = ttk.Frame(notebook)\n",
    "notebook.add(tab_main, text=\"Record & Classify\")\n",
    "notebook.add(tab_visualization, text=\"Visualizations\")\n",
    "notebook.add(tab_results, text=\"Results\")\n",
    "\n",
    "# Styles\n",
    "style = ttk.Style(root)\n",
    "style.theme_use(\"clam\")\n",
    "style.configure(\"TButton\", padding=6, relief=\"flat\", background=\"#2e2e3e\", foreground=\"white\", font=(\"Helvetica\", 10))\n",
    "style.configure(\"TLabel\", background=\"#1e1e2e\", foreground=\"white\", font=(\"Helvetica\", 12))\n",
    "style.configure(\"TNotebook\", background=\"#2e2e3e\", foreground=\"white\")\n",
    "style.configure(\"TNotebook.Tab\", font=(\"Helvetica\", 12), padding=[10, 5])\n",
    "\n",
    "# Record audio\n",
    "def record_audio(duration=DURATION, sr=SAMPLE_RATE):\n",
    "    global last_audio\n",
    "    status_label.config(text=\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1)\n",
    "    sd.wait()\n",
    "    last_audio = np.squeeze(audio)\n",
    "    status_label.config(text=\"Recording finished.\")\n",
    "    return last_audio\n",
    "\n",
    "# Preprocess audio to MFCC\n",
    "def preprocess_audio(audio, sr=SAMPLE_RATE, num_mfcc=NUM_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH, expected_len=EXPECTED_MFCC_LEN):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    if mfcc.shape[1] < expected_len:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, expected_len - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :expected_len]\n",
    "    return np.expand_dims(mfcc.T, axis=0)\n",
    "\n",
    "# Classify genre\n",
    "def classify_genre(audio_mfcc):\n",
    "    prediction = model.predict(audio_mfcc)\n",
    "    genre_index = np.argmax(prediction, axis=1)\n",
    "    genre_label = encoder.inverse_transform(genre_index)\n",
    "    confidence = prediction[0][genre_index[0]] * 100\n",
    "    return genre_label[0], confidence\n",
    "\n",
    "# Classify button function\n",
    "def classify_audio():\n",
    "    audio = record_audio()\n",
    "    audio_mfcc = preprocess_audio(audio)\n",
    "    genre, confidence = classify_genre(audio_mfcc)\n",
    "    \n",
    "    classification_history.append((datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), genre, confidence))\n",
    "    update_history_table()\n",
    "    \n",
    "    result_label.config(text=f\"Predicted Genre: {genre} \\nConfidence: {confidence:.2f}%\")\n",
    "    status_label.config(text=\"Classification Complete\")\n",
    "\n",
    "    # Fetch song suggestions based on the predicted genre\n",
    "    fetch_song_suggestions(genre)\n",
    "\n",
    "def fetch_song_suggestions(genre):\n",
    "    # Example of a simple song suggestion API\n",
    "    # Replace with an actual API URL that returns song suggestions based on genre\n",
    "    url = f\"http://example.com/api/songs?genre={genre}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            suggestions = response.json()  # Assuming the API returns a JSON response\n",
    "            suggestion_text = \"\\n\".join([f\"{song['title']} by {song['artist']}\" for song in suggestions])\n",
    "            messagebox.showinfo(\"Song Suggestions\", f\"Suggested Songs:\\n{suggestion_text}\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Could not fetch song suggestions.\")\n",
    "    except requests.RequestException as e:\n",
    "        messagebox.showerror(\"Error\", f\"Request failed: {str(e)}\")\n",
    "\n",
    "# Save recording\n",
    "def save_audio():\n",
    "    global last_audio\n",
    "    if last_audio is not None:\n",
    "        file_name = f\"recording_{random.randint(1000, 9999)}.wav\"\n",
    "        sf.write(file_name, last_audio, SAMPLE_RATE)\n",
    "        audio = AudioSegment.from_wav(file_name)\n",
    "        mp3_filename = file_name.replace('.wav', '.mp3')\n",
    "        audio.export(mp3_filename, format=\"mp3\", bitrate=\"320k\")\n",
    "        \n",
    "        messagebox.showinfo(\"Save Recording\", f\"Audio saved as {mp3_filename} at 320 kbps\")\n",
    "        status_label.config(text=\"Audio Saved at 320 kbps\")\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"No audio recorded to save.\")\n",
    "\n",
    "# Play recorded audio\n",
    "def play_audio():\n",
    "    global last_audio\n",
    "    if last_audio is not None:\n",
    "        status_label.config(text=\"Playing audio...\")\n",
    "        sd.play(last_audio, samplerate=SAMPLE_RATE)\n",
    "        sd.wait()\n",
    "        status_label.config(text=\"Playback finished.\")\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"No audio recorded to play.\")\n",
    "\n",
    "# Update classification history table\n",
    "def update_history_table():\n",
    "    for row in history_tree.get_children():\n",
    "        history_tree.delete(row)\n",
    "    for record in classification_history:\n",
    "        history_tree.insert(\"\", \"end\", values=record)\n",
    "\n",
    "# Generate confusion matrix\n",
    "def plot_confusion_matrix():\n",
    "    if not classification_history:\n",
    "        messagebox.showinfo(\"Info\", \"No classifications to generate confusion matrix.\")\n",
    "        return\n",
    "    \n",
    "    genres = [rec[1] for rec in classification_history]\n",
    "    unique_genres = sorted(set(genres))\n",
    "    cm = confusion_matrix(genres, genres, labels=unique_genres)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=unique_genres, yticklabels=unique_genres, cmap=\"Blues\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    canvas = FigureCanvasTkAgg(fig, master=tab_results)\n",
    "    canvas.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "    canvas.draw()\n",
    "\n",
    "# Display spectrogram\n",
    "def plot_spectrogram():\n",
    "    if last_audio is not None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        S = librosa.feature.melspectrogram(y=last_audio, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "        img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=SAMPLE_RATE, fmax=8000, ax=ax)\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "        ax.set_title(\"Mel Spectrogram\")\n",
    "        canvas = FigureCanvasTkAgg(fig, master=tab_visualization)\n",
    "        canvas.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "        canvas.draw()\n",
    "\n",
    "# Display MFCC\n",
    "def plot_mfcc():\n",
    "    if last_audio is not None:\n",
    "        mfcc = librosa.feature.mfcc(y=last_audio, sr=SAMPLE_RATE, n_mfcc=NUM_MFCC)\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        img = librosa.display.specshow(mfcc, x_axis='time', sr=SAMPLE_RATE, ax=ax)\n",
    "        ax.set_title(\"MFCC\")\n",
    "        fig.colorbar(img, ax=ax)\n",
    "        canvas = FigureCanvasTkAgg(fig, master=tab_visualization)\n",
    "        canvas.get_tk_widget().pack(fill=\"both\", expand=True)\n",
    "        canvas.draw()\n",
    "\n",
    "# Exit application\n",
    "def exit_application():\n",
    "    root.quit()\n",
    "\n",
    "# GUI Layout for Record & Classify\n",
    "frame = ttk.Frame(tab_main)\n",
    "frame.pack(pady=10)\n",
    "\n",
    "result_label = ttk.Label(frame, text=\"Predicted Genre will appear here\", font=(\"Helvetica\", 12), background=\"#1e1e2e\", foreground=\"#00ff00\")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "status_label = ttk.Label(frame, text=\"Status: Waiting...\", font=(\"Helvetica\", 10), background=\"#1e1e2e\", foreground=\"#ffdd00\")\n",
    "status_label.pack(pady=10)\n",
    "\n",
    "btn_frame = ttk.Frame(frame)\n",
    "btn_frame.pack(pady=10)\n",
    "\n",
    "ttk.Button(btn_frame, text=\"Record and Classify\", command=classify_audio).grid(row=0, column=0, padx=5)\n",
    "ttk.Button(btn_frame, text=\"Save Recording\", command=save_audio).grid(row=0, column=1, padx=5)\n",
    "ttk.Button(btn_frame, text=\"Play Recording\", command=play_audio).grid(row=0, column=2, padx=5)\n",
    "\n",
    "# Visualization Tab Layout\n",
    "visualization_frame = ttk.Frame(tab_visualization)\n",
    "visualization_frame.pack(pady=10)\n",
    "\n",
    "ttk.Button(visualization_frame, text=\"Plot Spectrogram\", command=plot_spectrogram).pack(side=\"left\", padx=5)\n",
    "ttk.Button(visualization_frame, text=\"Plot MFCC\", command=plot_mfcc).pack(side=\"left\", padx=5)\n",
    "\n",
    "# Results Tab Layout\n",
    "history_tree = ttk.Treeview(tab_results, columns=(\"Timestamp\", \"Genre\", \"Confidence\"), show=\"headings\")\n",
    "history_tree.heading(\"Timestamp\", text=\"Timestamp\")\n",
    "history_tree.heading(\"Genre\", text=\"Genre\")\n",
    "history_tree.heading(\"Confidence\", text=\"Confidence (%)\")\n",
    "history_tree.pack(expand=True, fill='both', padx=10, pady=10)\n",
    "\n",
    "# Buttons for results tab\n",
    "ttk.Button(tab_results, text=\"Generate Confusion Matrix\", command=plot_confusion_matrix).pack(pady=10)\n",
    "ttk.Button(tab_results, text=\"Exit\", command=exit_application).pack(pady=10)\n",
    "\n",
    "# Run the GUI loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0de18-ffb7-42e6-8530-fcdb3ce97191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
